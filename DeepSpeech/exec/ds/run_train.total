#! /usr/bin/env bash

cd ../.. > /dev/null

export FLAGS_sync_nccl_allreduce=0
CUDA_VISIBLE_DEVICES=0,1,2,3 \
python -u train.py \
--init_from_pretrained_model='./checkpoints/gru2/step_final' \
--batch_size=5 \
--num_epoch=50 \
--num_conv_layers=2 \
--num_rnn_layers=3 \
--rnn_layer_size=1024 \
--num_iter_print=1 \
--save_epoch=1 \
--num_samples=44000 \
--learning_rate=1e-04 \
--max_duration=22.0 \
--min_duration=1.5 \
--test_off=False \
--use_sortagrad=True \
--use_gru=True \
--use_gpu=True \
--is_local=True \
--share_rnn_weights=True \
--train_manifest='data/mpmg/manifest.val2' \
--dev_manifest='data/mpmg/manifest.val2' \
--mean_std_path='data/mpmg/mean_std.npz' \
--vocab_path='data/mpmg/vocab.txt' \
--output_model_dir='./checkpoints/gru2' \
--augment_conf_path='conf/augmentation.config' \
--specgram_type='linear' \
--shuffle_method='batch_shuffle_clipped' \

if [ $? -ne 0 ]; then
    echo "Failed in training!"
    exit 1
fi


exit 0
